---
layout: post
title: OpenPose で動作分析する1
description: OpenPose で動作分析する1
date: 2019-01-24T23:07:02
categories: openpose opencv motion
---

# OpenPoseで動作分析

動画から動作を抽出してみたいとおもって調べてみた。
OpenPoseというのを使うと簡単なようだ。
学習済みモデルがあるので、それを使ってまずは、動かしてみたい。
大きな目標としては、3次元のモデルを作ってみたい。

OpenPose記事をいくつか見つけた。
これらの記事は、ソースコードをもってきて、そこからモデルの学習からやっているようである。

しかしそのようなパワーのあるGPUをもっていないので、そのようなステップは飛ばして、
学習済みモデルだけ使って、動くかどうかだけを確認したい。

OpenPoseは現在

- 静止画像を解析してくれるようだ
  - 動画は、静止画像の連続に分解してそれを１枚づつ分析し、つなぎ合わせているようである。
- 3Dモデルを作ってくれるわけではないようだ
  - 3Dデータを取り出すところは現在研究しているようだ。

学習も行いたいが、GPUがないときは、[Google Colaboratory](https://colab.research.google.com/notebooks/welcome.ipynb)を使うという方法もあるみたい。
ということは、Azureのやつでもいけるのかな。同じようなのはAmazonにもあったかもしれない。


将来的には、動画をとってそのまま解析してもらいたいところではあるが、まずは動かしてみる。


- [GitHub - CMU-Perceptual-Computing-Lab/openpose: OpenPose: Real-time multi-person keypoint detection library for body, face, hands, and foot estimation](https://github.com/CMU-Perceptual-Computing-Lab/openpose)
    - 本家

- [OpenPoseを動かしてみた。 - Qiita](https://qiita.com/nnn_anoken/items/a4490d85dac5827db53b)
- [AI(Openpose)でバッティングフォーム解析 - Qiita](https://qiita.com/nanako_ut/items/1a9ce5d4eca672b38d2d)
- [OpenCVを使ったモーション テンプレート解析（リアルタイムに物体とその動く方向を認識する） - Qiita](https://qiita.com/hitomatagi/items/a4ecf7babdbe710208ae)
- [OpenCVで人数カウント 後編 - Qiita](https://qiita.com/c-nova/items/1e5d3495312680e2fb5b)
- [OpenPose試してみた。〜ディープラニングで人のポーズを解析](https://ledge.ai/openpose/)

- [Openposeの3D化に関する調査 - Qiita](https://qiita.com/tonouchi510/items/390b98a4db669168d662)
    - 3次元化する研究の調査

# 参考

## Google Colaboratory

PFNが Colaboratory の教材を作ってくださっているので、これも

- [Google Colaboratoryを用いた機械学習・深層学習の入門教材を無料公開（健康・医療向けデータを用いた実践編も含む） \| Preferred Research](https://research.preferred.jp/2018/12/medical-ai-course-materials/)

## DeepPose

別の実装で、DeepPoseというのもあるようだ

[機械学習のお勉強（DeepPose, OpenPose） - 空飛ぶロボットのつくりかた](http://robonchu.hatenablog.com/entry/2017/09/11/141836)
